{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "from gpflow.kernels.stationaries import SquaredExponential, Kernel, Matern52\n",
    "from tensorflow import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old stuff\n",
    "\n",
    "def old_k_grad_se(inducing_variable_ny, inducing_variable_Zy, kernel):\n",
    "    funcs2 = tf.range(inducing_variable_Zy.shape[0])\n",
    "    norm = 1 / (kernel.lengthscales ** 2)\n",
    "    partial_derivative = tf.map_fn(\n",
    "        lambda j: (inducing_variable_ny - inducing_variable_Zy[j]),\n",
    "        funcs2, fn_output_signature=tf.float64, parallel_iterations=8)\n",
    "    return norm * partial_derivative\n",
    "\n",
    "def old_kernel_derivative(\n",
    "        inducing_location_ny: Tensor,\n",
    "        inducing_location_Zy: Tensor,\n",
    "        kernel: Kernel,\n",
    "):\n",
    "    iterator = tf.range(inducing_location_ny.shape[0])\n",
    "    block = tf.map_fn(lambda i: old_k_grad_se(inducing_location_ny[i], inducing_location_Zy, kernel),\n",
    "                      iterator, fn_output_signature=tf.float64, parallel_iterations=8)\n",
    "\n",
    "    return block\n",
    "\n",
    "def initialize_Z(num_latent_gps, num_inducing):\n",
    "    Z = tf.convert_to_tensor(np.array(\n",
    "        [np.full(num_latent_gps, i) for i in np.linspace(0.1, 0.9, num_inducing)], dtype=np.float64))\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dof = 1\n",
    "from gpflow.base import default_float\n",
    "\n",
    "start = tf.cast((tf.fill((1, dof), 0.)), dtype=default_float())\n",
    "end = tf.cast((tf.fill((1, dof), 1.)), dtype=default_float())\n",
    "Z = initialize_Z(dof, 2)\n",
    "ny = tf.concat([start, end], axis=0)\n",
    "Zy = tf.concat([ny, Z], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 1), dtype=float64, numpy=\n",
       "array([[[ 0. ],\n",
       "        [-1. ],\n",
       "        [-0.1],\n",
       "        [-0.9]],\n",
       "\n",
       "       [[ 1. ],\n",
       "        [ 0. ],\n",
       "        [ 0.9],\n",
       "        [ 0.1]]])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_kernel_derivative(ny, Zy, SquaredExponential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kernel_derivative(ny, Zy, kernel):\n",
    "    lengthscale = kernel.lengthscales\n",
    "    block = new_k_grad_se(ny, Zy, lengthscale)\n",
    "    return block\n",
    "\n",
    "def new_k_grad_se(ny, Zy, lengthscale):\n",
    "    norm = 1 / (lengthscale ** 2)\n",
    "    partial_derivative = norm * tf.subtract(tf.expand_dims(ny, 1), Zy)\n",
    "    return partial_derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 7), dtype=float64, numpy=\n",
       "array([[[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "        [-1. , -1. , -1. , -1. , -1. , -1. , -1. ],\n",
       "        [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1],\n",
       "        [-0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ],\n",
       "        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "        [ 0.9,  0.9,  0.9,  0.9,  0.9,  0.9,  0.9],\n",
       "        [ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1]]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kernel_derivative(ny, Zy, SquaredExponential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4, 7), dtype=float64, numpy=\n",
       "array([[[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "        [-1. , -1. , -1. , -1. , -1. , -1. , -1. ],\n",
       "        [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1],\n",
       "        [-0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9]],\n",
       "\n",
       "       [[ 1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ],\n",
       "        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "        [ 0.9,  0.9,  0.9,  0.9,  0.9,  0.9,  0.9],\n",
       "        [ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1]],\n",
       "\n",
       "       [[ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1],\n",
       "        [-0.9, -0.9, -0.9, -0.9, -0.9, -0.9, -0.9],\n",
       "        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "        [-0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8]],\n",
       "\n",
       "       [[ 0.9,  0.9,  0.9,  0.9,  0.9,  0.9,  0.9],\n",
       "        [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1],\n",
       "        [ 0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8],\n",
       "        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ]]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kernel_derivative(Zy, Zy, SquaredExponential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_grad_grad_se_fallback(\n",
    "        inducing_location_ny: Tensor,\n",
    "        kernel: SquaredExponential,\n",
    "):\n",
    "    norm = kernel.lengthscales ** 2\n",
    "    inducing_diff = tf.expand_dims(inducing_location_ny, 1) - tf.expand_dims(inducing_location_ny, 0)\n",
    "    second_derivative = norm - inducing_diff ** 2\n",
    "    return second_derivative / kernel.lengthscales ** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def kernel_derivative(ny, Zy, kernel):\n",
    "\n",
    "    block_original = kernel(Zy)[..., None]\n",
    "    print(block_original.shape)\n",
    "    ny_block = k_grad_grad_se_fallback(ny, kernel) * block_original[:ny.shape[0], :ny.shape[0]]\n",
    "    print(ny_block.shape)\n",
    "    nyZy_block = new_kernel_derivative(ny, Zy[ny.shape[0]:], kernel) * block_original[:ny.shape[0], ny.shape[0]:]\n",
    "    print(nyZy_block.shape)\n",
    "    upper_block = tf.concat([ny_block, nyZy_block], axis=1)\n",
    "    lower_block = tf.concat([-tf.transpose(nyZy_block, perm=(1, 0, 2)), block_original[ny.shape[0]:, ny.shape[0]:]], axis=1)\n",
    "    return tf.concat([upper_block, lower_block], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 1)\n",
      "(2, 2, 1)\n",
      "(2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "aux = kernel_derivative(ny, Zy, SquaredExponential(lengthscales=.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4), dtype=float64, numpy=\n",
       "array([[[ 4.        , -1.6240234 , -0.39207947, -0.71243532],\n",
       "        [-1.6240234 ,  4.        ,  0.71243532,  0.39207947],\n",
       "        [ 0.39207947, -0.71243532,  1.        ,  0.2780373 ],\n",
       "        [ 0.71243532, -0.39207947,  0.2780373 ,  1.        ]]])>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(aux, perm=(2, 0 ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = SquaredExponential(lengthscales=.5)\n",
    "# tf.print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[0.],\n",
       "       [1.]])>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[-4.        , -0.54134113],\n",
       "       [-0.54134113, -4.        ]])>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ny[0] - ny[1])/(0.5 ** 2) * kk(ny) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float64, numpy=\n",
       "array([[[ 0.        ,  0.        ],\n",
       "        [-0.54134113, -4.        ]],\n",
       "\n",
       "       [[ 4.        ,  0.54134113],\n",
       "        [ 0.        ,  0.        ]]])>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kernel_derivative(ny, ny, kk) * kk(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgpmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f01e6a756d1939fec269a02bc8944db8b372d9c47942ed0978bffe99fee7403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
